#!/usr/bin/env python3
"""
URL ìš°ì„ ìˆœìœ„ ëª©ë¡ ìƒì„±ê¸°

koreaners.coì˜ ëª¨ë“  í˜ì´ì§€ URLì„ ì¶”ì¶œí•˜ê³  ìš°ì„ ìˆœìœ„ë¥¼ ì§€ì •í•˜ì—¬
CSV ë° Excel íŒŒì¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python url_priority_generator.py

ì¶œë ¥ íŒŒì¼:
    - url_priority_list.csv
    - indexing_schedule.xlsx (openpyxl ì„¤ì¹˜ ì‹œ)
"""

import csv
import os
import sys
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import json

# Supabase í´ë¼ì´ì–¸íŠ¸ (í•„ìš”ì‹œ)
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("âš ï¸  supabase-py ë¯¸ì„¤ì¹˜. pip install supabase ì‹¤í–‰")

# Excel ì§€ì› (ì„ íƒì )
try:
    from openpyxl import Workbook
    from openpyxl.styles import Font, PatternFill, Alignment
    from openpyxl.utils import get_column_letter
    EXCEL_AVAILABLE = True
except ImportError:
    EXCEL_AVAILABLE = False
    print("âš ï¸  openpyxl ë¯¸ì„¤ì¹˜. pip install openpyxl ì‹¤í–‰ (Excel ì¶œë ¥ í•„ìš”ì‹œ)")


# í™˜ê²½ ë³€ìˆ˜
SUPABASE_URL = os.getenv('NEXT_PUBLIC_SUPABASE_URL', '')
SUPABASE_KEY = os.getenv('NEXT_PUBLIC_SUPABASE_ANON_KEY', '')
BASE_URL = 'https://www.koreaners.co'


class URLPriorityGenerator:
    """URL ìš°ì„ ìˆœìœ„ ìƒì„± ë° ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.base_url = BASE_URL
        self.urls: List[Dict] = []
        self.supabase: Optional[Client] = None

        if SUPABASE_AVAILABLE and SUPABASE_URL and SUPABASE_KEY:
            self.supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

    def add_static_pages(self):
        """ì •ì  í˜ì´ì§€ ì¶”ê°€"""
        static_pages = [
            {
                'url': self.base_url,
                'title': 'ì½”ë¦¬ë„ˆìŠ¤ í™ˆ',
                'priority': 'Critical',
                'priority_score': 1.0,
                'estimated_traffic': 'ë†’ìŒ',
                'category': 'ë©”ì¸',
                'indexing_status': 'í™•ì¸ í•„ìš”',
                'index_date': None,
            },
            {
                'url': f'{self.base_url}/portfolio',
                'title': 'í¬íŠ¸í´ë¦¬ì˜¤',
                'priority': 'Critical',
                'priority_score': 0.9,
                'estimated_traffic': 'ë†’ìŒ',
                'category': 'ì£¼ìš” ì„œë¹„ìŠ¤',
                'indexing_status': 'í™•ì¸ í•„ìš”',
                'index_date': None,
            },
            {
                'url': f'{self.base_url}/blog',
                'title': 'ë¸”ë¡œê·¸',
                'priority': 'Critical',
                'priority_score': 0.9,
                'estimated_traffic': 'ë†’ìŒ',
                'category': 'ì£¼ìš” ì„œë¹„ìŠ¤',
                'indexing_status': 'í™•ì¸ í•„ìš”',
                'index_date': None,
            },
            {
                'url': f'{self.base_url}/creator',
                'title': 'í¬ë¦¬ì—ì´í„° í•©ë¥˜',
                'priority': 'High',
                'priority_score': 0.8,
                'estimated_traffic': 'ì¤‘ê°„',
                'category': 'ì„œë¹„ìŠ¤',
                'indexing_status': 'í™•ì¸ í•„ìš”',
                'index_date': None,
            },
            {
                'url': f'{self.base_url}/inquiry',
                'title': 'ë¬¸ì˜í•˜ê¸°',
                'priority': 'Medium',
                'priority_score': 0.7,
                'estimated_traffic': 'ì¤‘ê°„',
                'category': 'ì„œë¹„ìŠ¤',
                'indexing_status': 'í™•ì¸ í•„ìš”',
                'index_date': None,
            },
        ]

        self.urls.extend(static_pages)
        print(f"âœ… ì •ì  í˜ì´ì§€ {len(static_pages)}ê°œ ì¶”ê°€")

    def add_dynamic_pages(self):
        """ë™ì  í˜ì´ì§€ ì¶”ê°€ (Supabaseì—ì„œ ê°€ì ¸ì˜¤ê¸°)"""
        if not self.supabase:
            print("âš ï¸  Supabase ì—°ê²° ì—†ìŒ. ë™ì  í˜ì´ì§€ ìŠ¤í‚µ")
            return

        try:
            # í¬íŠ¸í´ë¦¬ì˜¤ í˜ì´ì§€
            portfolios = self.supabase.table('portfolios').select('id, title, created_at').execute()
            for portfolio in portfolios.data:
                self.urls.append({
                    'url': f'{self.base_url}/portfolio/{portfolio["id"]}',
                    'title': f'í¬íŠ¸í´ë¦¬ì˜¤: {portfolio.get("title", "ì œëª© ì—†ìŒ")}',
                    'priority': 'High',
                    'priority_score': 0.8,
                    'estimated_traffic': 'ì¤‘ê°„',
                    'category': 'í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„¸',
                    'indexing_status': 'í™•ì¸ í•„ìš”',
                    'index_date': None,
                })
            print(f"âœ… í¬íŠ¸í´ë¦¬ì˜¤ í˜ì´ì§€ {len(portfolios.data)}ê°œ ì¶”ê°€")

            # ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸
            blog_posts = self.supabase.table('blog_posts').select('id, title, published, created_at').eq('published', True).execute()
            for post in blog_posts.data:
                self.urls.append({
                    'url': f'{self.base_url}/blog/{post["id"]}',
                    'title': f'ë¸”ë¡œê·¸: {post.get("title", "ì œëª© ì—†ìŒ")}',
                    'priority': 'Medium',
                    'priority_score': 0.7,
                    'estimated_traffic': 'ë‚®ìŒ-ì¤‘ê°„',
                    'category': 'ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸',
                    'indexing_status': 'í™•ì¸ í•„ìš”',
                    'index_date': None,
                })
            print(f"âœ… ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ {len(blog_posts.data)}ê°œ ì¶”ê°€")

            # í¬ë¦¬ì—ì´í„° í”„ë¡œí•„
            creators = self.supabase.table('creators').select('id, name, created_at').execute()
            for creator in creators.data:
                self.urls.append({
                    'url': f'{self.base_url}/creator/{creator["id"]}',
                    'title': f'í¬ë¦¬ì—ì´í„°: {creator.get("name", "ì´ë¦„ ì—†ìŒ")}',
                    'priority': 'Low',
                    'priority_score': 0.6,
                    'estimated_traffic': 'ë‚®ìŒ',
                    'category': 'í¬ë¦¬ì—ì´í„° í”„ë¡œí•„',
                    'indexing_status': 'í™•ì¸ í•„ìš”',
                    'index_date': None,
                })
            print(f"âœ… í¬ë¦¬ì—ì´í„° í”„ë¡œí•„ {len(creators.data)}ê°œ ì¶”ê°€")

        except Exception as e:
            print(f"âŒ ë™ì  í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

    def calculate_index_dates(self):
        """ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ì¸ë±ì‹± ì˜ˆìƒ ë‚ ì§œ ê³„ì‚°"""
        priority_schedule = {
            'Critical': 0,  # ì¦‰ì‹œ
            'High': 7,      # 1ì£¼ì¼ ì´ë‚´
            'Medium': 14,   # 2ì£¼ì¼ ì´ë‚´
            'Low': 30,      # 1ê°œì›” ì´ë‚´
        }

        today = datetime.now()
        for url_info in self.urls:
            priority = url_info['priority']
            days_offset = priority_schedule.get(priority, 30)
            url_info['index_date'] = (today + timedelta(days=days_offset)).strftime('%Y-%m-%d')

    def sort_by_priority(self):
        """ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬"""
        self.urls.sort(key=lambda x: x['priority_score'], reverse=True)

    def export_to_csv(self, filename='url_priority_list.csv'):
        """CSV íŒŒì¼ë¡œ ì¶œë ¥"""
        if not self.urls:
            print("âŒ ì¶œë ¥í•  URLì´ ì—†ìŠµë‹ˆë‹¤")
            return

        fieldnames = [
            'url', 'title', 'priority', 'priority_score',
            'estimated_traffic', 'category', 'indexing_status', 'index_date'
        ]

        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.urls)

        print(f"âœ… CSV íŒŒì¼ ìƒì„±: {filename} ({len(self.urls)}ê°œ URL)")

    def export_to_excel(self, filename='indexing_schedule.xlsx'):
        """Excel íŒŒì¼ë¡œ ì¶œë ¥ (ê³ ê¸‰ í¬ë§·íŒ…)"""
        if not EXCEL_AVAILABLE:
            print("âš ï¸  Excel ì¶œë ¥ ë¶ˆê°€: openpyxl ë¯¸ì„¤ì¹˜")
            return

        if not self.urls:
            print("âŒ ì¶œë ¥í•  URLì´ ì—†ìŠµë‹ˆë‹¤")
            return

        wb = Workbook()
        ws = wb.active
        ws.title = "ì¸ë±ì‹± ìŠ¤ì¼€ì¤„"

        # í—¤ë” ìŠ¤íƒ€ì¼
        header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')
        header_font = Font(bold=True, color='FFFFFF')

        # í—¤ë” ì‘ì„±
        headers = ['URL', 'í˜ì´ì§€ ì œëª©', 'ìš°ì„ ìˆœìœ„', 'ìš°ì„ ìˆœìœ„ ì ìˆ˜',
                   'ì˜ˆìƒ íŠ¸ë˜í”½', 'ì¹´í…Œê³ ë¦¬', 'ì¸ë±ì‹± ìƒíƒœ', 'ì˜ˆìƒ ì¸ë±ì‹± ë‚ ì§œ']
        for col_num, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col_num, value=header)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal='center', vertical='center')

        # ë°ì´í„° ì‘ì„±
        for row_num, url_info in enumerate(self.urls, 2):
            ws.cell(row=row_num, column=1, value=url_info['url'])
            ws.cell(row=row_num, column=2, value=url_info['title'])
            ws.cell(row=row_num, column=3, value=url_info['priority'])
            ws.cell(row=row_num, column=4, value=url_info['priority_score'])
            ws.cell(row=row_num, column=5, value=url_info['estimated_traffic'])
            ws.cell(row=row_num, column=6, value=url_info['category'])
            ws.cell(row=row_num, column=7, value=url_info['indexing_status'])
            ws.cell(row=row_num, column=8, value=url_info['index_date'])

            # ìš°ì„ ìˆœìœ„ë³„ ìƒ‰ìƒ
            priority_colors = {
                'Critical': 'FF6B6B',
                'High': 'FFA500',
                'Medium': 'FFD93D',
                'Low': '95E1D3',
            }
            priority_fill = PatternFill(
                start_color=priority_colors.get(url_info['priority'], 'FFFFFF'),
                end_color=priority_colors.get(url_info['priority'], 'FFFFFF'),
                fill_type='solid'
            )
            ws.cell(row=row_num, column=3).fill = priority_fill

        # ì—´ ë„ˆë¹„ ìë™ ì¡°ì •
        for col_num in range(1, len(headers) + 1):
            column_letter = get_column_letter(col_num)
            max_length = len(headers[col_num - 1])
            for row in ws.iter_rows(min_col=col_num, max_col=col_num):
                for cell in row:
                    if cell.value:
                        max_length = max(max_length, len(str(cell.value)))
            ws.column_dimensions[column_letter].width = min(max_length + 2, 50)

        wb.save(filename)
        print(f"âœ… Excel íŒŒì¼ ìƒì„±: {filename} ({len(self.urls)}ê°œ URL)")

    def generate(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ URL ìš°ì„ ìˆœìœ„ ëª©ë¡ ìƒì„± ì‹œì‘\n")

        self.add_static_pages()
        self.add_dynamic_pages()
        self.calculate_index_dates()
        self.sort_by_priority()

        print(f"\nğŸ“Š ì´ {len(self.urls)}ê°œ URL ìƒì„± ì™„ë£Œ\n")

        # ìš°ì„ ìˆœìœ„ë³„ í†µê³„
        priority_counts = {}
        for url_info in self.urls:
            priority = url_info['priority']
            priority_counts[priority] = priority_counts.get(priority, 0) + 1

        print("ğŸ“ˆ ìš°ì„ ìˆœìœ„ë³„ í†µê³„:")
        for priority, count in sorted(priority_counts.items(),
                                     key=lambda x: ['Critical', 'High', 'Medium', 'Low'].index(x[0])):
            print(f"   - {priority}: {count}ê°œ")

        print()
        self.export_to_csv()
        self.export_to_excel()

        print("\nâœ… ì™„ë£Œ!")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    generator = URLPriorityGenerator()
    generator.generate()


if __name__ == '__main__':
    main()

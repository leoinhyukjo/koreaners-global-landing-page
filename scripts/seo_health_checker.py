#!/usr/bin/env python3
"""
SEO Health Checker

ì›¹ì‚¬ì´íŠ¸ì˜ SEO ìƒíƒœë¥¼ ì •ê¸°ì ìœ¼ë¡œ ì ê²€í•˜ê³  ë¬¸ì œë¥¼ ë³´ê³ í•©ë‹ˆë‹¤.

ì ê²€ í•­ëª©:
- robots.txt ì ‘ê·¼ì„±
- sitemap.xml ìœ íš¨ì„±
- í˜ì´ì§€ ì‘ë‹µ ì‹œê°„
- ë©”íƒ€ íƒœê·¸ ì¡´ì¬ ì—¬ë¶€
- ëª¨ë°”ì¼ ì¹œí™”ì„±
- HTTPS ì„¤ì •

ì‚¬ìš©ë²•:
    python seo_health_checker.py

"""

import requests
import xml.etree.ElementTree as ET
from typing import Dict, List, Tuple
from datetime import datetime
import json
import time

BASE_URL = 'https://www.koreaners.co'
TIMEOUT = 10


class SEOHealthChecker:
    """SEO ìƒíƒœ ì ê²€ í´ë˜ìŠ¤"""

    def __init__(self, base_url: str = BASE_URL):
        self.base_url = base_url.rstrip('/')
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'base_url': self.base_url,
            'checks': {},
            'score': 0,
            'issues': [],
            'warnings': [],
            'success': []
        }

    def check_robots_txt(self) -> Tuple[bool, str]:
        """robots.txt ì ê²€"""
        try:
            url = f'{self.base_url}/robots.txt'
            response = requests.get(url, timeout=TIMEOUT)

            if response.status_code == 200:
                content = response.text

                # ê¸°ë³¸ ê²€ì¦
                has_user_agent = 'User-agent:' in content
                has_sitemap = 'Sitemap:' in content

                if has_user_agent and has_sitemap:
                    return True, "âœ… robots.txt ì •ìƒ (User-agent, Sitemap í¬í•¨)"
                elif has_user_agent:
                    return True, "âš ï¸  robots.txt ì¡´ì¬í•˜ì§€ë§Œ Sitemap ì„ ì–¸ ëˆ„ë½"
                else:
                    return False, "âŒ robots.txt í˜•ì‹ ì˜¤ë¥˜"
            else:
                return False, f"âŒ robots.txt ì ‘ê·¼ ì‹¤íŒ¨ (HTTP {response.status_code})"

        except requests.RequestException as e:
            return False, f"âŒ robots.txt ì ‘ê·¼ ì˜¤ë¥˜: {e}"

    def check_sitemap_xml(self) -> Tuple[bool, str]:
        """sitemap.xml ì ê²€"""
        try:
            url = f'{self.base_url}/sitemap.xml'
            response = requests.get(url, timeout=TIMEOUT)

            if response.status_code == 200:
                try:
                    # XML íŒŒì‹±
                    root = ET.fromstring(response.content)

                    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì²˜ë¦¬
                    ns = {'sm': 'http://www.sitemaps.org/schemas/sitemap/0.9'}
                    urls = root.findall('.//sm:url', ns)

                    if urls:
                        return True, f"âœ… sitemap.xml ì •ìƒ ({len(urls)}ê°œ URL)"
                    else:
                        return False, "âš ï¸  sitemap.xmlì— URL ì—†ìŒ"

                except ET.ParseError:
                    return False, "âŒ sitemap.xml XML íŒŒì‹± ì˜¤ë¥˜"
            else:
                return False, f"âŒ sitemap.xml ì ‘ê·¼ ì‹¤íŒ¨ (HTTP {response.status_code})"

        except requests.RequestException as e:
            return False, f"âŒ sitemap.xml ì ‘ê·¼ ì˜¤ë¥˜: {e}"

    def check_page_response(self, path: str = '') -> Tuple[bool, str]:
        """í˜ì´ì§€ ì‘ë‹µ ì‹œê°„ ì ê²€"""
        try:
            url = f'{self.base_url}{path}'
            start_time = time.time()
            response = requests.get(url, timeout=TIMEOUT)
            response_time = time.time() - start_time

            if response.status_code == 200:
                if response_time < 2.0:
                    return True, f"âœ… ë¹ ë¥¸ ì‘ë‹µ ({response_time:.2f}ì´ˆ)"
                elif response_time < 5.0:
                    return True, f"âš ï¸  ì‘ë‹µ ëŠë¦¼ ({response_time:.2f}ì´ˆ)"
                else:
                    return False, f"âŒ ì‘ë‹µ ë§¤ìš° ëŠë¦¼ ({response_time:.2f}ì´ˆ)"
            else:
                return False, f"âŒ HTTP {response.status_code}"

        except requests.RequestException as e:
            return False, f"âŒ ì ‘ê·¼ ì˜¤ë¥˜: {e}"

    def check_https(self) -> Tuple[bool, str]:
        """HTTPS ì„¤ì • ì ê²€"""
        if self.base_url.startswith('https://'):
            try:
                response = requests.get(self.base_url, timeout=TIMEOUT)
                if response.url.startswith('https://'):
                    return True, "âœ… HTTPS ì •ìƒ (ë¦¬ë‹¤ì´ë ‰íŠ¸ ì—†ìŒ)"
                else:
                    return False, "âš ï¸  HTTPë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¨"
            except requests.RequestException as e:
                return False, f"âŒ HTTPS ì ‘ê·¼ ì˜¤ë¥˜: {e}"
        else:
            return False, "âŒ HTTPS ë¯¸ì‚¬ìš©"

    def check_meta_tags(self, path: str = '') -> Tuple[bool, str]:
        """ë©”íƒ€ íƒœê·¸ ì ê²€"""
        try:
            url = f'{self.base_url}{path}'
            response = requests.get(url, timeout=TIMEOUT)

            if response.status_code == 200:
                html = response.text.lower()

                has_title = '<title>' in html
                has_description = 'name="description"' in html or 'property="og:description"' in html
                has_og_tags = 'property="og:' in html
                has_canonical = 'rel="canonical"' in html

                issues = []
                if not has_title:
                    issues.append("title íƒœê·¸ ì—†ìŒ")
                if not has_description:
                    issues.append("description ì—†ìŒ")
                if not has_og_tags:
                    issues.append("OG íƒœê·¸ ì—†ìŒ")
                if not has_canonical:
                    issues.append("canonical íƒœê·¸ ì—†ìŒ")

                if not issues:
                    return True, "âœ… ëª¨ë“  ë©”íƒ€ íƒœê·¸ ì¡´ì¬"
                elif len(issues) <= 2:
                    return True, f"âš ï¸  ì¼ë¶€ íƒœê·¸ ëˆ„ë½: {', '.join(issues)}"
                else:
                    return False, f"âŒ ì¤‘ìš” íƒœê·¸ ëˆ„ë½: {', '.join(issues)}"
            else:
                return False, f"âŒ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨ (HTTP {response.status_code})"

        except requests.RequestException as e:
            return False, f"âŒ ì ‘ê·¼ ì˜¤ë¥˜: {e}"

    def run_all_checks(self):
        """ëª¨ë“  ì ê²€ ì‹¤í–‰"""
        print("ğŸ” SEO Health Check ì‹œì‘\n")

        checks = [
            ("robots.txt", self.check_robots_txt()),
            ("sitemap.xml", self.check_sitemap_xml()),
            ("HTTPS", self.check_https()),
            ("í™ˆí˜ì´ì§€ ì‘ë‹µ", self.check_page_response('/')),
            ("í™ˆí˜ì´ì§€ ë©”íƒ€ íƒœê·¸", self.check_meta_tags('/')),
        ]

        total_score = 0
        max_score = len(checks)

        for name, (success, message) in checks:
            self.results['checks'][name] = {
                'success': success,
                'message': message
            }

            if success:
                total_score += 1
                if "âœ…" in message:
                    self.results['success'].append(f"{name}: {message}")
                else:
                    self.results['warnings'].append(f"{name}: {message}")
            else:
                self.results['issues'].append(f"{name}: {message}")

            print(f"{'âœ…' if success else 'âŒ'} {name}: {message}")

        self.results['score'] = int((total_score / max_score) * 100)

        print(f"\nğŸ“Š ì¢…í•© ì ìˆ˜: {self.results['score']}/100")
        print(f"   - ì„±ê³µ: {len(self.results['success'])}")
        print(f"   - ê²½ê³ : {len(self.results['warnings'])}")
        print(f"   - ë¬¸ì œ: {len(self.results['issues'])}")

        # ê²°ê³¼ ì €ì¥
        with open('seo_health_report.json', 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥: seo_health_report.json")

        return self.results

    def generate_text_report(self) -> str:
        """í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        lines = []
        lines.append("=" * 60)
        lines.append("SEO Health Check ë¦¬í¬íŠ¸")
        lines.append("=" * 60)
        lines.append(f"ì ê²€ ì¼ì‹œ: {self.results['timestamp']}")
        lines.append(f"ëŒ€ìƒ ì‚¬ì´íŠ¸: {self.results['base_url']}")
        lines.append(f"ì¢…í•© ì ìˆ˜: {self.results['score']}/100")
        lines.append("")

        if self.results['success']:
            lines.append("âœ… ì •ìƒ í•­ëª©:")
            for item in self.results['success']:
                lines.append(f"  â€¢ {item}")
            lines.append("")

        if self.results['warnings']:
            lines.append("âš ï¸  ê²½ê³  í•­ëª©:")
            for item in self.results['warnings']:
                lines.append(f"  â€¢ {item}")
            lines.append("")

        if self.results['issues']:
            lines.append("âŒ ë¬¸ì œ í•­ëª©:")
            for item in self.results['issues']:
                lines.append(f"  â€¢ {item}")
            lines.append("")

        lines.append("=" * 60)

        report = "\n".join(lines)

        with open('seo_health_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)

        return report


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    checker = SEOHealthChecker()
    checker.run_all_checks()
    report = checker.generate_text_report()

    print(f"\n{report}")


if __name__ == '__main__':
    main()
